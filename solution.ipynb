{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-1-8df04e2c",
        "language": "markdown"
      },
      "source": [
        "# Iteration 0: Setup & Data Download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-2-d6079237",
        "language": "markdown"
      },
      "source": [
        "GPU-accelerated forecasting with CuPy and Polars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-3-ebd29ce5",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import cupy as np\n",
        "import sys\n",
        "import os\n",
        "import subprocess\n",
        "import zipfile\n",
        "\n",
        "# Check GPU\n",
        "try:\n",
        "    print(f\"Python: {sys.executable}\")\n",
        "    devs = np.cuda.runtime.getDeviceCount()\n",
        "    print(f\"✓ GPU: {devs} device(s), CuPy {np.__version__}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ GPU Error: {e}\")\n",
        "\n",
        "# Download Data\n",
        "def download_data(comp=\"ts-forecasting\"):\n",
        "    if os.path.exists(\"data/train.parquet\"):\n",
        "        print(\"✓ Data exists.\")\n",
        "        return\n",
        "    os.makedirs(\"data\", exist_ok=True)\n",
        "    env = os.environ.copy()\n",
        "    env[\"KAGGLE_USERNAME\"] = \"dummy_user\"\n",
        "    env[\"KAGGLE_KEY\"] = \"KGAT_ccc00b322d3c4b85f0036a23cc420469\"\n",
        "    try:\n",
        "        subprocess.run([\"kaggle\", \"competitions\", \"download\", \"-c\", comp], check=True, env=env)\n",
        "        with zipfile.ZipFile(f\"{comp}.zip\", 'r') as z: z.extractall(\"data\")\n",
        "        os.remove(f\"{comp}.zip\")\n",
        "        print(\"✓ Downloaded.\")\n",
        "    except: print(\"✗ Download failed.\")\n",
        "\n",
        "download_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-6-400274e1",
        "language": "markdown"
      },
      "source": [
        "# Iteration 2: Imports & Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-7-1e72ad7d",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import warnings\n",
        "import os\n",
        "import gc\n",
        "import lightgbm as lgb\n",
        "import cupy as np\n",
        "import numpy as np_cpu\n",
        "from typing import Tuple, List, Dict\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    try:\n",
        "        np.get_default_memory_pool().free_all_blocks()\n",
        "    except: pass\n",
        "\n",
        "def gpu_to_cpu(x):\n",
        "    if x is None: return None\n",
        "    try:\n",
        "        if isinstance(x, (float, int, np_cpu.generic)): return x\n",
        "        return x.get() if hasattr(x, 'get') else np_cpu.asarray(x)\n",
        "    except: return np_cpu.asarray(x)\n",
        "\n",
        "def cpu_to_gpu(x):\n",
        "    return np.asarray(x) if x is not None else None\n",
        "\n",
        "def weighted_rmse_score(y_true, y_pred, weights) -> float:\n",
        "    y_t, y_p, w = np.asarray(y_true), np.asarray(y_pred), np.asarray(weights)\n",
        "    score = 1 - np.sqrt(np.sum(w * (y_t - y_p)**2) / (np.sum(w * y_t**2) + 1e-8))\n",
        "    return float(gpu_to_cpu(score))\n",
        "\n",
        "def fast_eval(df_tr, df_va, feats, target=\"feature_ch\", weight=\"feature_cg\"):\n",
        "    \"\"\"Quick LGBM eval for iteration tracking.\"\"\"\n",
        "    X_tr = df_tr.select(feats).fill_null(0).to_numpy()\n",
        "    y_tr, w_tr = df_tr[target].to_numpy(), df_tr[weight].fill_null(1.0).to_numpy()\n",
        "    X_va = df_va.select(feats).fill_null(0).to_numpy()\n",
        "    y_va, w_va = df_va[target].to_numpy(), df_va[weight].fill_null(1.0).to_numpy()\n",
        "    \n",
        "    m = lgb.LGBMRegressor(n_estimators=100, device=\"gpu\", random_state=42, verbose=-1)\n",
        "    m.fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "    return weighted_rmse_score(cpu_to_gpu(y_va), cpu_to_gpu(m.predict(X_va)), cpu_to_gpu(w_va))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-8-cff11c58",
        "language": "markdown"
      },
      "source": [
        "# Iteration A: Load Data & Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-9-74ab4d34",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "def load_and_split_data(train_path=\"data/train.parquet\", test_path=\"data/test.parquet\", valid_ratio=0.2):\n",
        "    print(f\"Loading {train_path}...\")\n",
        "    def optimize(df):\n",
        "        return df.with_columns([\n",
        "            pl.col(c).cast(pl.Float32) for c, t in df.schema.items() if t == pl.Float64\n",
        "        ] + [\n",
        "            pl.col(c).cast(pl.Categorical) for c, t in df.schema.items() if t == pl.Utf8 or t == pl.String\n",
        "        ])\n",
        "\n",
        "    train_full = optimize(pl.read_parquet(train_path))\n",
        "    test_df = optimize(pl.read_parquet(test_path))\n",
        "    \n",
        "    max_ts = train_full[\"ts_index\"].max()\n",
        "    split_ts = max_ts - int((max_ts - train_full[\"ts_index\"].min()) * valid_ratio)\n",
        "    \n",
        "    train_df = train_full.filter(pl.col(\"ts_index\") < split_ts)\n",
        "    valid_df = train_full.filter(pl.col(\"ts_index\") >= split_ts)\n",
        "    del train_full\n",
        "    clear_memory()\n",
        "\n",
        "    excl = [\"id\", \"code\", \"sub_code\", \"sub_category\", \"feature_ch\", \"feature_cg\", \"ts_index\", \"horizon\"]\n",
        "    feats = [c for c in train_df.columns if c not in excl]\n",
        "    return train_df, valid_df, test_df, feats\n",
        "\n",
        "train_df, valid_df, test_df, feature_cols = load_and_split_data()\n",
        "\n",
        "# Baseline\n",
        "y_val = train_df[\"feature_ch\"].mean()\n",
        "y_true_gpu = cpu_to_gpu(valid_df[\"feature_ch\"].to_numpy())\n",
        "w_gpu = cpu_to_gpu(valid_df[\"feature_cg\"].fill_null(1.0).to_numpy())\n",
        "score_a = weighted_rmse_score(y_true_gpu, np.full_like(y_true_gpu, y_val), w_gpu)\n",
        "print(f\"Iteration A Score: {score_a:.4f} | Baseline=Mean | Features={len(feature_cols)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-10-fac6ca26",
        "language": "markdown"
      },
      "source": [
        "# Iteration B: Temporal Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-11-c69eccda",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "def create_temporal_features_pl(df, feats, group_cols=[\"code\", \"sub_code\"], windows=[7, 30]):\n",
        "    # Optimized: process more features (30 instead of 15) to avoid detail loss\n",
        "    to_proc = feats[:30]\n",
        "    print(f\"Creating temporal features for {len(to_proc)} base features...\")\n",
        "    \n",
        "    df = df.sort(group_cols + [\"ts_index\"])\n",
        "    batch_size = 5\n",
        "    for i in range(0, len(to_proc), batch_size):\n",
        "        batch = to_proc[i:i+batch_size]\n",
        "        exprs = []\n",
        "        for f in batch:\n",
        "            exprs.append(pl.col(f).shift(1).over(group_cols).alias(f\"{f}_lag1\").cast(pl.Float32))\n",
        "            for w in windows:\n",
        "                exprs.append(pl.col(f).shift(1).rolling_mean(w, min_periods=1).over(group_cols).alias(f\"{f}_rm{w}\").cast(pl.Float32))\n",
        "        df = df.with_columns(exprs)\n",
        "        clear_memory()\n",
        "    return df\n",
        "\n",
        "# Prepare for feature creation\n",
        "train_df = train_df.with_columns(pl.lit(\"train\").alias(\"set\"))\n",
        "valid_df = valid_df.with_columns(pl.lit(\"valid\").alias(\"set\"))\n",
        "test_df = test_df.with_columns(pl.lit(\"test\").alias(\"set\"))\n",
        "\n",
        "full_df = pl.concat([train_df, valid_df, test_df], how=\"diagonal\")\n",
        "del train_df, valid_df, test_df\n",
        "full_df = create_temporal_features_pl(full_df, feature_cols)\n",
        "\n",
        "# Split back\n",
        "train_df = full_df.filter(pl.col(\"set\") == \"train\")\n",
        "valid_df = full_df.filter(pl.col(\"set\") == \"valid\")\n",
        "test_df = full_df.filter(pl.col(\"set\") == \"test\")\n",
        "del full_df\n",
        "clear_memory()\n",
        "\n",
        "current_features = [c for c in train_df.columns if c not in [\"id\", \"code\", \"sub_code\", \"sub_category\", \"feature_ch\", \"feature_cg\", \"ts_index\", \"horizon\", \"set\"]]\n",
        "score_b = fast_eval(train_df, valid_df, current_features)\n",
        "print(f\"Iteration B Score: {score_b:.4f} | Δ: {score_b - score_a:+.4f} | Features: {len(current_features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-12-ab6508f7",
        "language": "markdown"
      },
      "source": [
        "# Iteration C: Weighted LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-13-cae6d238",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "def train_horizon_model(df, feats, h):\n",
        "    df_h = df.filter(pl.col(\"horizon\") == h).sort(\"ts_index\")\n",
        "    split_ts = df_h[\"ts_index\"].unique().sort()[int(len(df_h[\"ts_index\"].unique())*0.9)]\n",
        "    \n",
        "    tr = df_h.filter(pl.col(\"ts_index\") < split_ts)\n",
        "    va = df_h.filter(pl.col(\"ts_index\") >= split_ts)\n",
        "    \n",
        "    dtrain = lgb.Dataset(tr.select(feats).fill_null(0).to_numpy(), tr[\"feature_ch\"], weight=tr[\"feature_cg\"].fill_null(1.0))\n",
        "    dvalid = lgb.Dataset(va.select(feats).fill_null(0).to_numpy(), va[\"feature_ch\"], weight=va[\"feature_cg\"].fill_null(1.0), reference=dtrain)\n",
        "    \n",
        "    m = lgb.train({\"objective\":\"regression\",\"metric\":\"rmse\",\"learning_rate\":0.05,\"num_leaves\":31,\"device\":\"gpu\",\"verbose\":-1},\n",
        "                  dtrain, num_boost_round=500, valid_sets=[dvalid], callbacks=[lgb.early_stopping(50), lgb.log_evaluation(False)])\n",
        "    return m\n",
        "\n",
        "print(\"Training Horizon models (Iteration C)...\")\n",
        "horizons = sorted(train_df[\"horizon\"].unique().to_list())\n",
        "models_c = {h: train_horizon_model(train_df, current_features, h) for h in horizons}\n",
        "\n",
        "# Evaluation\n",
        "valid_df = valid_df.with_columns(pl.lit(0.0).alias(\"pred_c\"))\n",
        "for h, m in models_c.items():\n",
        "    mask = (pl.col(\"horizon\") == h)\n",
        "    if valid_df.filter(mask).height > 0:\n",
        "        preds = m.predict(valid_df.filter(mask).select(current_features).fill_null(0).to_numpy())\n",
        "        valid_df = valid_df.with_columns(pl.when(mask).then(pl.Series(preds)).otherwise(pl.col(\"pred_c\")).alias(\"pred_c\"))\n",
        "\n",
        "score_c = weighted_rmse_score(y_true_gpu, cpu_to_gpu(valid_df[\"pred_c\"]), w_gpu)\n",
        "print(f\"Iteration C Score: {score_c:.4f} | Δ: {score_c - score_b:+.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-14-a930987a",
        "language": "markdown"
      },
      "source": [
        "# Iteration D: PCA Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-15-92b9313d",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "print(\"PCA Dimensionality Reduction (Iteration D)...\")\n",
        "\n",
        "pca_feats = [c for c in train_df.columns if \"_rm\" in c or \"_lag\" in c][:40]\n",
        "\n",
        "def get_pca(df_tr, df_va, df_te, cols, n=8):\n",
        "    X_tr = df_tr.select(cols).fill_null(0).to_numpy()\n",
        "    mean, std = X_tr.mean(axis=0), X_tr.std(axis=0)\n",
        "    std[std == 0] = 1.0\n",
        "    \n",
        "    pca = PCA(n_components=n)\n",
        "    tr_pca = pca.fit_transform((X_tr - mean) / std)\n",
        "    va_pca = pca.transform((df_va.select(cols).fill_null(0).to_numpy() - mean) / std)\n",
        "    te_pca = pca.transform((df_te.select(cols).fill_null(0).to_numpy() - mean) / std)\n",
        "    return tr_pca, va_pca, te_pca\n",
        "\n",
        "tr_p, va_p, te_p = get_pca(train_df, valid_df, test_df, pca_feats)\n",
        "pca_cols = [f\"pca_{i}\" for i in range(8)]\n",
        "\n",
        "train_df = pl.concat([train_df, pl.DataFrame(tr_p, schema=pca_cols).with_columns(pl.all().cast(pl.Float32))], how=\"horizontal\")\n",
        "valid_df = pl.concat([valid_df, pl.DataFrame(va_p, schema=pca_cols).with_columns(pl.all().cast(pl.Float32))], how=\"horizontal\")\n",
        "test_df = pl.concat([test_df, pl.DataFrame(te_p, schema=pca_cols).with_columns(pl.all().cast(pl.Float32))], how=\"horizontal\")\n",
        "\n",
        "features_d = current_features + pca_cols\n",
        "score_d = fast_eval(train_df, valid_df, features_d)\n",
        "print(f\"Iteration D Score: {score_d:.4f} | Δ: {score_d - score_c:+.4f} | Features: {len(features_d)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-16-0035b3f9",
        "language": "markdown"
      },
      "source": [
        "# Iteration E: Target Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-17-f0ac8086",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "def smoothed_enc(df, col, target=\"feature_ch\", smoothing=10):\n",
        "    g_mean = df[target].mean()\n",
        "    base = df.select([col, target]).with_columns([\n",
        "        pl.col(target).shift(1).cum_sum().over(col).fill_null(0).alias(\"sum\"),\n",
        "        pl.col(target).shift(1).cum_count().over(col).fill_null(0).alias(\"cnt\")\n",
        "    ])\n",
        "    return ((base[\"sum\"] + smoothing * g_mean) / (base[\"cnt\"] + smoothing)).cast(pl.Float32)\n",
        "\n",
        "print(\"Target Encoding (Iteration E)...\")\n",
        "full = pl.concat([train_df.select([\"code\",\"sub_code\",\"feature_ch\"]), \n",
        "                  valid_df.select([\"code\",\"sub_code\",\"feature_ch\"]),\n",
        "                  test_df.select([\"code\",\"sub_code\",\"feature_ch\"])], how=\"vertical\")\n",
        "\n",
        "for c in [\"code\", \"sub_code\"]:\n",
        "    enc = smoothed_enc(full, c)\n",
        "    train_df = train_df.with_columns(enc.slice(0, train_df.height).alias(f\"{c}_enc\"))\n",
        "    valid_df = valid_df.with_columns(enc.slice(train_df.height, valid_df.height).alias(f\"{c}_enc\"))\n",
        "    test_df = test_df.with_columns(enc.slice(train_df.height + valid_df.height, test_df.height).alias(f\"{c}_enc\"))\n",
        "\n",
        "features_e = features_d + [\"code_enc\", \"sub_code_enc\"]\n",
        "score_e = fast_eval(train_df, valid_df, features_e)\n",
        "print(f\"Iteration E Score: {score_e:.4f} | Δ: {score_e - score_d:+.4f} | Features: {len(features_e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-18-cb056bb2",
        "language": "markdown"
      },
      "source": [
        "# Iteration F: Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-19-b7815232",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"Feature Selection (Iteration F)...\")\n",
        "\n",
        "# Importance selection\n",
        "X_np = train_df.select(features_e).fill_null(0).to_numpy()\n",
        "y_np = train_df[\"feature_ch\"].to_numpy()\n",
        "m_sel = lgb.LGBMRegressor(n_estimators=100, device=\"gpu\", random_state=42, verbose=-1)\n",
        "m_sel.fit(X_np, y_np)\n",
        "\n",
        "importance = pl.DataFrame({\"f\": features_e, \"i\": m_sel.feature_importances_}).sort(\"i\", descending=True)\n",
        "selected_feats = importance.head(150)[\"f\"].to_list()\n",
        "\n",
        "score_f = fast_eval(train_df, valid_df, selected_feats)\n",
        "print(f\"Iteration F Score: {score_f:.4f} | Δ: {score_f - score_e:+.4f} | Top Features: {selected_feats[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cell-20-d5c54363",
        "language": "markdown"
      },
      "source": [
        "# Iteration G: Ensemble (LightGBM + XGBoost + CatBoost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cell-21-08c00070",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "print(\"Ensemble Training (Iteration G)...\")\n",
        "valid_df = valid_df.with_columns(pl.lit(0.0).alias(\"pred_g\"))\n",
        "test_preds = []\n",
        "\n",
        "for h in horizons:\n",
        "    tr = train_df.filter(pl.col(\"horizon\") == h)\n",
        "    va = valid_df.filter(pl.col(\"horizon\") == h)\n",
        "    te = test_df.filter(pl.col(\"horizon\") == h)\n",
        "    \n",
        "    X_tr = tr.select(selected_feats).fill_null(0).to_numpy()\n",
        "    y_tr, w_tr = tr[\"feature_ch\"].to_numpy(), tr[\"feature_cg\"].fill_null(1.0).to_numpy()\n",
        "    X_va = va.select(selected_feats).fill_null(0).to_numpy()\n",
        "    X_te = te.select(selected_feats).fill_null(0).to_numpy()\n",
        "    \n",
        "    # Simple weighted ensemble\n",
        "    m1 = lgb.LGBMRegressor(n_estimators=500, device=\"gpu\", verbose=-1).fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "    m2 = xgb.XGBRegressor(n_estimators=500, tree_method=\"hist\", device=\"cuda\").fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "    m3 = CatBoostRegressor(n_estimators=500, task_type=\"GPU\", verbose=0).fit(X_tr, y_tr, sample_weight=w_tr)\n",
        "    \n",
        "    p_va = 0.4*m1.predict(X_va) + 0.4*m2.predict(X_va) + 0.2*m3.predict(X_va)\n",
        "    p_te = 0.4*m1.predict(X_te) + 0.4*m2.predict(X_te) + 0.2*m3.predict(X_te)\n",
        "    \n",
        "    valid_df = valid_df.with_columns(pl.when(pl.col(\"horizon\")==h).then(pl.Series(p_va)).otherwise(pl.col(\"pred_g\")).alias(\"pred_g\"))\n",
        "    test_preds.append(te.select(\"id\").with_columns(pl.Series(\"prediction\", p_te)))\n",
        "    clear_memory()\n",
        "\n",
        "score_g = weighted_rmse_score(y_true_gpu, cpu_to_gpu(valid_df[\"pred_g\"]), w_gpu)\n",
        "pl.concat(test_preds).write_csv(\"submission_final_polars.csv\")\n",
        "print(f\"Iteration G Score: {score_g:.4f} | Δ: {score_g - score_f:+.4f} | Saved submission.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
